{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d763c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext jupyter_black\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from lightning.pytorch import seed_everything\n",
    "import datasets\n",
    "from util import MLPRegressor, train\n",
    "from sentiment import SentimentClassifier\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (25000, 768), Test: (25000, 768)\n"
     ]
    }
   ],
   "source": [
    "with open('data/gemma_train_random_crop_10_50.json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('data/gemma_test_random_crop_10_50.json') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "X_train = np.array(train_data['mean'], dtype=np.float32)\n",
    "y_train = np.array(train_data['label'], dtype=np.float32)\n",
    "X_test = np.array(test_data['mean'], dtype=np.float32)\n",
    "y_test = np.array(test_data['label'], dtype=np.float32)\n",
    "\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True, generator=generator\n",
    ")\n",
    "test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c8ed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Epoch 1/1:   0%|          | 0/782 [00:00<?, ?it/s, loss=0.6600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 782/782 [00:03<00:00, 234.30it/s, loss=0.1616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1  train_loss=0.4541  val_loss=0.4342  roc_auc=0.8810  accuracy=0.7910\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.454086</td>\n",
       "      <td>0.434186</td>\n",
       "      <td>0.880964</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  val_loss   roc_auc  accuracy\n",
       "0      1    0.454086  0.434186  0.880964     0.791"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "model = MLPRegressor(input_size=X_train.shape[1], hidden_size=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "df = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    epochs=1,\n",
    "    val_loader=test_loader,\n",
    "    score_fns={\n",
    "        'roc_auc': lambda y, p: roc_auc_score(y, p),\n",
    "        'accuracy': lambda y, p: accuracy_score(y, p > 0.5),\n",
    "    },\n",
    "    output_fn=torch.sigmoid,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to data/sentiment_head.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'data/sentiment_head.pt')\n",
    "print('Saved model to data/sentiment_head.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined model\n"
     ]
    }
   ],
   "source": [
    "classifier = SentimentClassifier(\n",
    "    model_name='google/embeddinggemma-300m',\n",
    "    hidden_size=10,\n",
    "    device=device,\n",
    ")\n",
    "classifier.load_head('data/sentiment_head.pt')\n",
    "print('Loaded combined model')\n",
    "assert sum(p.requires_grad for p in classifier.parameters()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6ce52",
   "metadata": {},
   "source": [
    "# Check on given inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999 (positive): This movie was absolutely fantastic! I loved every minute of...\n",
      "0.000 (negative): Terrible film. Waste of time and money. Do not recommend....\n",
      "0.997 (positive): The acting was superb and the plot kept me engaged throughou...\n",
      "0.000 (negative): Boring and predictable. I fell asleep halfway through....\n",
      "0.997 (positive): A masterpiece of cinema. One of the best films I have ever s...\n",
      "0.000 (negative): Awful movie with terrible acting and a nonsensical plot....\n",
      "0.324 (negative): I don't know, quite average movie...\n",
      "0.487 (negative): Not to my taste, but others might like it...\n",
      "0.721 (positive): A good enough movie for an evening...\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "    'This movie was absolutely fantastic! I loved every minute of it.',\n",
    "    'Terrible film. Waste of time and money. Do not recommend.',\n",
    "    'The acting was superb and the plot kept me engaged throughout.',\n",
    "    'Boring and predictable. I fell asleep halfway through.',\n",
    "    'A masterpiece of cinema. One of the best films I have ever seen.',\n",
    "    'Awful movie with terrible acting and a nonsensical plot.',\n",
    "    'I don\\'t know, quite average movie',\n",
    "    'Not to my taste, but others might like it',\n",
    "    'A good enough movie for an evening',\n",
    "]\n",
    "\n",
    "predictions = classifier.predict(test_texts)\n",
    "\n",
    "for text, pred in zip(test_texts, predictions):\n",
    "    sentiment = 'positive' if pred > 0.5 else 'negative'\n",
    "    print(f'{pred:.3f} ({sentiment}): {text[:60]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a414a",
   "metadata": {},
   "source": [
    "# Final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9764\n",
      "Accuracy: 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "imdb = datasets.load_dataset('imdb')\n",
    "test_subset = imdb['test'].shuffle(seed=42).select(range(500))\n",
    "\n",
    "batch_size = 64\n",
    "all_preds = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_subset), batch_size)):\n",
    "    batch_texts = test_subset['text'][i : i + batch_size]\n",
    "    preds = classifier.predict(batch_texts).cpu().numpy()\n",
    "    all_preds.extend(preds)\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(test_subset['label'])\n",
    "\n",
    "print(f'ROC AUC: {roc_auc_score(all_labels, all_preds):.4f}')\n",
    "print(f'Accuracy: {accuracy_score(all_labels, all_preds > 0.5):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b058c8a",
   "metadata": {},
   "source": [
    "# Study model mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60ff7152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: 1, predicted: 0.3447573482990265\n",
      "i was having a horrid day but this movie grabbed me, and i couldn't put it down until the end... and i had forgotten about my horrid day. and the ending... by the way... where is the sequel!!!<br /><br />the budget is obviously extremely low... but ... look what they did with it! it reminds me of a play... they are basically working with a tent, a 'escape pod', a few guns, uniforms, camping gear, and a 'scanner' thing. that is it for props. Maybe this is even a good thing, forcing the acting and writing to have to step up and take their rightful place in film, as the centers of the work, instead of as afterthoughts used to have an excuse to make CGI fights (starwars).<br /><br />The cgi is fine. It is not exactly 'seamless'... but imho it still works. why? because there isn't too much of it, and what there is, is not 'taking over' with an army of effects house people trying to cram everything they can into the shot. it prompts the imagination... it's some relatively simple stuff, with decent composition (especially the heavy freighter shot.. there is one long shot that must be at least ten seconds...that tracks the entire length of the ship... it must be a record for sci fi battle sequence film making in the past 10 years, to have an action sequence that lasts longer than 0.75 seconds), and some relation to the story. it might look old or not 'state of the art', but it doesn't look stupid and it doesn't take away from the story.<br /><br />The acting is good, except the characters die too fast to get to know them. The captain was great, but a few of his scenes could have used another take. I also got confused with his character losing his cool and stomping on a corpse, I like to think captains are calm cool and in control... what was going on in that scene? did the other crew worry about him losing it at that moment? did he feel himself losing control? <br /><br />Now, as for the plot.... mostly it is good... why? Because it doesn't try to explain itself. It just happens. It's called 'the planet', its a mystery, get it?? Nobody knows why there is a statue, and they don't find out either. The mysterious cult? The weird scientist with the tattoo? What do you expect to find out in less than 90 minutes? This isn't War and Peace. And, thank god, it's not star wars/trek either. No midichlorians, no 5 minutes of expository boring dialog that has no purpose in the story. The characters are stranded, and are only able to figure out a few basic things... it is not a star trek episode where they find out it's leonardo davinci or a child like space wanderer. It is mysterious, and i liked that. I don't know why, maybe I can identify with these guys more , since they don't know whats happening, and i don't either... they don't talk a lot of space gibberish or have magic boxes telling them what is happening. <br /><br />In fact, I would argue that one of the weakest moments is when the 'traitor' turns on the crew, and tries to 'explain' the reason for the planet, the cult, etc. This coincidentally has some of the weakest dialog, imho, in the whole movie, and it interrupts the flow and some of the characters look unnatural in that scene. <br /><br />OK, sometimes I felt it was a little too mysterious, though. Like, why did the guy get fried through his eyes with lightning? That was odd. Just weird. The 'hamlet' ending... again I would have liked to have known some of these characters better. And would it have been so hard to have a 30 second rescue scene at the end? This is not a serial show, it was a film, and we like closure in films, even if they can have a sequel. Imagine Hamlet with no 'flights of angels sing thee to thy rest'<br /><br />Anyways. What can I say. This was well worth the dollar I payed at the 'red box' machine at the supermarket. It was also, imho, a better piece of storytelling than starwars parts 1 2 or 3. Like I said, it sucked me in, wanting to know what was happening, and I couldn't stop watching until the end.\n",
      "\n",
      "real: 1, predicted: 0.2234790325164795\n",
      "Great cult flick for MST-3K types: Richard Boone is a mess -- bad hair, arthritis, even his dark glasses aren't right; about as good as a bad dino-flick can get... actually, that charging saber-toothed Styracosaurus was pretty cool -- maybe Spielberg should take a couple of notes from that one.\n",
      "\n",
      "real: 1, predicted: 0.23532135784626007\n",
      "I have fond memories of watching this when it came out. It's one of those films that you know is rubbish, even when you're a kid, but at that age you overlook the ludicrous acting, special effects and plot (so there's a race of big-busted nymphets living underground, huh?) and just enjoy the campy monsters for all they're worth.\n",
      "\n",
      "real: 1, predicted: 0.14474071562290192\n",
      "Bears about as much resemblance to Dean Koontz's novel as Jessica Simpson does to a rocket scientist. If you've read the book, I suggest you put it as far out of your mind as possible before watching the movie.<br /><br />Watchers is your typical \"Boy meets dog, dog turns out to be super-intelligent government lab experiment, dog and boy are pursued by super-intelligent and emotionally disturbed monster created by same lab, and, oh yeah, did I mention the shady government agents pursuing the monster pursuing the dog?\" movie.<br /><br />Corey Haim is the boy, Barbara Williams is his mother, Michael Ironside is one of the evil government guys, and Sandy the dog is, well, the dog (named Furface here; Einstein in the book).<br /><br />The monster effects are ridiculously cheesy, much of the dialogue is laughable, the script rarely makes sense or is believable - a good example is Haim's character's unquestioning acceptance of the dog's intelligence, as if every Fido off the street can type messages on a computer keyboard or bark once for yes and twice for no! Hmm, it's gotta be the puppy chow, right? Haim's performance is enthusiastic but shaky, as he carries off the stupid dialogue with the least amount of skill. Ironside has been the highlight of many a bad movie, and this is no exception. He easily gives the best performance of the movie, although I'm compelled to add that the dog (who's a pretty darn good actor himself!) comes in a close second.<br /><br />All in all, an atrociously dumb movie, and yet . . . And yet I watched it three times within a week. And yet I can't help liking it. Hey, what can I say, I have a taste for junk - and Michael Ironside (not that I've ever actually tasted Michael Ironside- I'm sure there are laws against that). But any movie that can make me laugh that hard (yes, even unintentionally) can't be all bad. Chalk it up to a guilty pleasure, a \"yes I know it's insultingly stupid but I like it anyway\" movie.<br /><br />It's tough for me to rate this. On a normal scale I'm forced to give it a D-, but on my own personal cheese scale, it gets bumped up to an A-.<br /><br />Yeah, I know. I'm weird like that.\n",
      "\n",
      "real: 1, predicted: 0.33141306042671204\n",
      "I don't understand why this movie has such a low rating. It totally deserves more! Sure, it's completely ridiculous, but that's what it was supposed to be. Don't expect cinematic transcendence from a movie about beauty pageant contestants stranded on a Caribbean island! What you should expect is a huge spoof of pretty much every relevant sci-fi, fantasy and block-buster movie in cinematic history, and even references to other spoofers. All completely exaggerated and sometimes totally unnecessary, but that's exactly what makes this movie stand out. If you like parodies, and enjoy say, Leslie Nielsen or Mike Myers, you're gonna love this. I sure did!\n",
      "\n",
      "real: 1, predicted: 0.18171577155590057\n",
      "I'm going to make this short and sweet. It's not surprising that you had no use for this film. This is a story about the power, beauty and possibilities inherent in a meaningful education. Based on your pathetically composed comments I can see that your own education has been woefully neglected... or worse... completely wasted. Your comments are those of a truly ignorant person. I would advise you to do something about this condition... but in your case I feel it's probably too late. My hope is that you yourself don't intend to go into the teaching profession ( especially in Film Studies) because you could only do damage. Oh... one last bit of advice. In the future, if you intend to write more opinion pieces, you should really proofread your work. It will make people take you more seriously.\n",
      "\n",
      "real: 1, predicted: 0.292728990316391\n",
      "This was easily one of the weirder of the Ernest movies, especially in regards to the production design. What was up with the pink guard uniforms? Sadly, this film probably destroyed the Ernest series, turning the series into a straight-to-video series. However, Jim Varney gave one of his better performances by playing Nash, his criminal alter ego. A misstep in the series, but wasn't too bad in most regards.(the Electro Man routine was classic)\n",
      "\n",
      "real: 1, predicted: 0.34509387612342834\n",
      "For those who expect documentaries to be objective creatures, let me give you a little lesson in American film-making.<br /><br />Documentaries rely heavily on casting. You pick and choose characters you think will enhance the drama and entertainment value of your film.<br /><br />After you have shot a ton of footage, you splice it together to make a film with ups and downs, turning points, climaxes, etc. If you have trouble with existing footage, you either shoot some more that makes sense, find some stock footage, or be clever with your narration.<br /><br />The allegation that the filmmakers used footage of locales not part of the movie (favelas next to beautiful beaches) does not detract from the value of the film as a dramatic piece and the particular image is one that resonates enough to justify its not-quite-truthful inclusion. At any rate, you use the footage you can. So they didn't happen to have police violence footage for that particular neighborhood. Does this mean not include it and just talk about it or maybe put in some cartoon animation so the audience isn't \"duped\"? Um, no.<br /><br />As for the hopeful ending, why not? Yes, Americans made it. Yes, Americans are optimistic bastards. But why end on a down note? Just because it's set in a foreign country and foreign films by and large end on a down note? Let foreigners portray the dismal outlook of life.<br /><br />Let us Americans think there may be a happy ending looming in the future. There just may be one.\n",
      "\n",
      "real: 1, predicted: 0.01972034014761448\n",
      "This HAS to be my guilty pleasure. I am a HUGE fan of 80's movies that were designed to entertain and they didn't care if they offended anyone. This move has no meat, not substance, no deep thought provoking scenes. Just plain old college kids having fun and if a few breasts have to be shown, then so be it! This movie is for when you just want to relax and NOT think. Viva la nudity!\n",
      "\n",
      "real: 1, predicted: 0.28879010677337646\n",
      "_The Wild Life_ has an obvious resemblance to _Fast Times At Ridgemont High_, and _The Wild Life_ comes up short.<br /><br />------------ <br /><br />Some other stan wrote the above comment. Of course The Wild Life is no Ridgemont. Ridgemont is the quintessential 80s flica. However, the Wild Life is enjoyable if you're not whiny about mindless movies being mindless movies (especially when you know it's supposed to be a mindless movie in the first place). The little Latino from Scarface is in this movie and he's straight disrespectful (\"I got Visa...Masterrrrr Charrrrge!!\") The Colonel also makes an appearance (\"Lawsuit...\"). RIP The Colonel 1931-1997.<br /><br />This movie is no worse than a 6 in comparison to other genres, btw. It is no worse than a 7 in terms of other 80s teen comedies at that. It does very much have the feel of a Cameron Crowe movie. Only staniels gave it a 5.\n"
     ]
    }
   ],
   "source": [
    "error_indices = np.where((all_labels - all_preds) > 0.6)[0]\n",
    "errors = test_subset.select(error_indices)\n",
    "error_predictions = all_preds[error_indices]\n",
    "print(\n",
    "    '\\n\\n'.join(\n",
    "        f'real: {label}, predicted: {pred}\\n{text}'\n",
    "        for label, text, pred in itertools.islice(\n",
    "            zip(\n",
    "                errors['label'],\n",
    "                errors['text'],\n",
    "                error_predictions,\n",
    "            ),\n",
    "            10,\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b4189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
