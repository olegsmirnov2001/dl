{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc167e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext jupyter_black\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d081a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from util.train import train\n",
    "from util.mlp_regressor import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f38cf03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62719170",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "with open('data/train.json') as inp:\n",
    "    data['train'] = json.load(inp)\n",
    "\n",
    "with open('data/test.json') as inp:\n",
    "    data['test'] = json.load(inp)\n",
    "\n",
    "with open('data/train_random_crop_10_50.json') as inp:\n",
    "    data['train_random_crop'] = json.load(inp)\n",
    "\n",
    "with open('data/test_random_crop_10_50.json') as inp:\n",
    "    data['test_random_crop'] = json.load(inp)\n",
    "\n",
    "for dct in data.values():\n",
    "    for key in dct:\n",
    "        dct[key] = np.array(dct[key], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cfc111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half done\n"
     ]
    }
   ],
   "source": [
    "with open('data/train_random_crop_10_50.json') as inp:\n",
    "    data['train_random_crop'] = json.load(inp)\n",
    "\n",
    "for dct in data.values():\n",
    "    for key in dct:\n",
    "        dct[key] = np.array(dct[key], dtype=np.float16)\n",
    "\n",
    "print('Half done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80eca96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test_random_crop_10_50.json') as inp:\n",
    "    data['test_random_crop'] = json.load(inp)\n",
    "\n",
    "for dct in data.values():\n",
    "    for key in dct:\n",
    "        dct[key] = np.array(dct[key], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1bcd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dct in data.values():\n",
    "    dct['label'] = dct['label'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f64e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/dl/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9820981440000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(verbose=True, max_iter=500, C=0.5)\n",
    "lr.fit(data['train']['mean'], data['train']['label'])\n",
    "y_test = lr.predict_proba(data['test']['mean'])\n",
    "roc_auc_score(data['test']['label'], y_test[:, 1])  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac41253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9358)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy:', (data['test']['label'] == (y_test[:, 1] > 0.5)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f6e41db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/dl/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8886\n",
      "Roc auc: 0.957001696\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(verbose=True, max_iter=500, C=0.5)\n",
    "lr.fit(data['train']['max'], data['train']['label'])\n",
    "y_test = lr.predict_proba(data['test']['max'])\n",
    "print('Accuracy:', (data['test']['label'] == (y_test[:, 1] > 0.5)).mean())\n",
    "print('Roc auc:', roc_auc_score(data['test']['label'], y_test[:, 1]))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c2f0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(variant: str, train_name: str, test_name: str, emb_method: str) -> pd.DataFrame:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_np = scaler.fit_transform(data[train_name][emb_method])\n",
    "    X_train = torch.tensor(X_train_np, dtype=torch.float32, device=device)\n",
    "    y_train = torch.tensor(data[train_name]['label'], dtype=torch.float32, device=device)\n",
    "\n",
    "    val_idx = np.random.choice(len(data[test_name][emb_method]), size=5000, replace=False)\n",
    "    X_val_np = scaler.transform(data[test_name][emb_method][val_idx])\n",
    "    X_val = torch.tensor(X_val_np, dtype=torch.float32, device=device)\n",
    "    y_val = torch.tensor(data[test_name]['label'][val_idx], dtype=torch.float32, device=device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_train, y_train),\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_val, y_val),\n",
    "        batch_size=5000,\n",
    "    )\n",
    "\n",
    "    model = MLPRegressor(input_size=X_train.shape[1], hidden_size=10).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    df = train(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        epochs=1,\n",
    "        score_fns={\n",
    "            'val_roc_auc': lambda y, p: roc_auc_score(y, p),\n",
    "        },\n",
    "        output_fn=torch.sigmoid,\n",
    "    )\n",
    "    df['train_name'] = train_name\n",
    "    df['test_name'] = test_name\n",
    "    df['emb_method'] = emb_method\n",
    "    df['variant'] = variant\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe0811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / test / mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / test / min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / test / max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / test / first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / test / last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_random_crop / test_random_crop / mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_random_crop / test_random_crop / min\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for variant, train_name, test_name in [\n",
    "    ('full', 'train', 'test'),\n",
    "    ('random_crop', 'train_random_crop', 'test_random_crop'),\n",
    "    ('mixed', 'train_random_crop', 'test'),\n",
    "    ('decreasing', 'train', 'test_random_crop'),\n",
    "]:\n",
    "    for emb_method in ['mean', 'min', 'max', 'first', 'last']:\n",
    "        print(f'{train_name} / {test_name} / {emb_method}')\n",
    "        results.append(\n",
    "            run_experiment(\n",
    "                variant=variant,\n",
    "                train_name=train_name,\n",
    "                test_name=test_name,\n",
    "                emb_method=emb_method,\n",
    "            )\n",
    "        )\n",
    "\n",
    "all_metrics_df = pd.concat(results, ignore_index=True)\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587eee65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9358)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Accuracy:', (data['test']['label'] == (y_test[:, 1] > 0.5)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971906c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics = all_metrics_df.groupby(['train_name', 'test_name', 'emb_method']).last().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=final_metrics,\n",
    "    x='emb_method',\n",
    "    y='val_roc_auc',\n",
    "    hue='variant',\n",
    "    palette={'full': 'blue', 'random_crop': 'red', 'mixed': 'green', 'decreasing': 'orange'},\n",
    "    order=['mean', 'last', 'first', 'min', 'max'],\n",
    "    hue_order=['full', 'random_crop', 'mixed', 'decreasing'],\n",
    ")\n",
    "plt.xlabel('emb_method')\n",
    "plt.ylabel('val_roc_auc')\n",
    "plt.legend(title='variant')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cd0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
